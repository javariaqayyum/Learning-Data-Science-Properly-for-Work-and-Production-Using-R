## Theoretical Lessons Learned

Very First and basic thing I have learned what is EDA? 
The actual meaning of EDA like this is Exploratory data analysis. we need to understand and explore dataset bafore performing any sort of preprocess or data cleaning.
For example if we consider Jobsdata, first thing we did is to explore most important or most relevant variables by making tables getting thier values percentages and making g
graph visualization.

I focused on work step by step that the next step must define or in squence of the previous on other than working randomly.
For example before i was working like 

Before
Read the data set  ----> Directly making bar cahrt of Jobstatus and Job completed ----> making bar chart of ContractorType and JobCompleted

After 
Read the data set --> Summary --> shorlisted the variable --> Tables and chart of every shorlisted variables -- > table of every shorlisted variable with Jobcomleted with perc --> Graph representation of each .... 

we need to focus on variables or information which we have early stages when job is comming or assign in machine learning/ deep learning algo otherwise we'll face
leakage and get wrong accuracy.

The other important thing i have learned we need to use tidyverse instead of base R. 

Difference between bar chart and histogram. For categorical values we use bar chart and quantitative values we use histogram.

Basic understanding of confusion matrix. what is the meaning and significance of every value in confusion matrix.
For example if we take cancer case model pridiction to interprate the results. First thing we understand by seeing the model is on rows we have actual values and on columns
we have model pridicted values. In first row first column we have values which are correctly classified as a cancer and in actual have cancer.
In last row last column we have values that are actually non-cancer and correctly pridicted by model as non-cancer. The other values are wrongly classified for
example model pridict that is not have cancer but actually classified as cancer person.

## R Programming Lessons Learned

How to make tables of visualization and unique values of variables with percentage to understand data. For example
df %>% group_by("variables name") %>% count()%>% perc()

Prefer tidyverse pipes instead of Base R.

Make 2*2 tables. 

If we use same long chunk of code again and again then make function of that and use this function. It improves quality of code.
for example instead of using 
data %>% ungroup() %>% mutate(Percentage = (n/sum(n))*100)
just make function and use perc(data).

